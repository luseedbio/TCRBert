{\rtf1\ansi\ansicpg949\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset129 AppleMyungjo;\f1\froman\fcharset0 Palatino-Roman;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\sl288\slmult1\pardirnatural\partightenfactor0

\f0\fs26 \cf0 \'c3\'d6\'b1\'d9\'c0\'c7
\f1  NLP
\f0 \'bf\'a1\'bc\'ad\'c0\'c7
\f1  
\f0 \'b9\'df\'c0\'fc\'b5\'e9\'c0\'ba
\f1  
\f0 \'c0\'da\'b1\'e2\'c1\'d6\'b5\'b5
\f1  
\f0 \'c7\'d0\'bd\'c0\'c0\'cc
\f1  unlabeled 
\f0 sequence \'b5\'a5\'c0\'cc\'c5\'cd\'b7\'ce\'ba\'ce\'c5\'cd \'c0\'af\'bf\'eb\'c7\'d1 \'c1\'a4\'ba\'b8\'b8\'a6 \'bb\'cc\'be\'c6\'b3\'bb\'b4\'c2\'b5\'a5 powerful\'c7\'d1 \'b5\'b5\'b1\'b8\'b6\'f3\'b4\'c2 \'b0\'cd\'c0\'bb \'c1\'f5\'b8\'ed\'c7\'cf\'bf\'b4\'b4\'d9[\{Peters:2018vk\}, \{Devlin:2018uk\}, \{Radford:2019vn\}]. One successful approach, BERT[\{Devlin et al., 2018\}]\
\}]\'b4\'c2 masked language model\'b0\'fa next token prediction \'b5\'ee\'c0\'c7 self-supervised bidrectional \'bc\'b1\'c7\'e0\'c7\'d0\'bd\'c0 \'be\'f0\'be\'ee \'b8\'f0\'b5\'a8\'c0\'bb \'b1\'b8\'c3\'e0\'c7\'cf\'b0\'ed \'c0\'cc\'b8\'a6 11\'b0\'b3\'c0\'c7 downstream tasks\'bf\'a1\'bc\'ad SOTA\'b8\'a6 \'b4\'de\'bc\'ba\'c7\'cf\'bf\'b4\'b4\'d9.\
\'c0\'cc\'b7\'af\'c7\'d1 self-supervised transfer learning \'c0\'fc\'b7\'ab, - \'c1\'ef unlabeled \'b4\'eb\'bf\'eb\'b7\'ae\'c0\'c7 \'b5\'a5\'c0\'cc\'c5\'cd\'bc\'c2\'b8\'a6 \'bb\'e7\'bf\'eb\'c7\'cf\'bf\'a9 self-supervised pretraining\'b5\'c8 \'b8\'f0\'b5\'a8\'c0\'bb downstream task\'bf\'a1\'bc\'ad \'c0\'fb\'c0\'ba \'bc\'f6\'c0\'c7 \'b5\'a5\'c0\'cc\'c5\'cd\'bc\'c2\'c0\'b8\'b7\'ce finetuning\'c7\'cf\'bf\'a9 \'c3\'d6\'c1\'be \'b8\'f0\'b5\'a8\'c0\'bb \'b1\'b8\'c3\'e0\'c7\'cf\'b4\'c2 \'c0\'fc\'b7\'ab - \'c0\'ba \'c7\'d0\'bd\'c0\'b5\'a5\'c0\'cc\'c5\'cd\'bc\'c2\'c0\'cc \'ba\'ce\'c1\'b7\'c7\'d1 task\'bf\'a1\'bc\'ad \'bd\'c5\'b7\'da\'c7\'d2 \'b8\'b8 \'bf\'b9\'c3\'f8 \'b8\'f0\'b5\'a8\'c0\'bb \'b1\'b8\'c3\'e0\'c7\'cf\'b4\'c2\'b5\'a5 \'c8\'bf\'b0\'fa\'c0\'fb\'c0\'cc\'b4\'d9.\
}