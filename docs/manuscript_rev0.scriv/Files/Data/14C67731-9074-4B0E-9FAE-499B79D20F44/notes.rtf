{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c100000;}
\deftab720
\pard\pardeftab720\sl260\sa240\partightenfactor0

\f0\fs21\fsmilli10667 \cf2 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\sl260\sa240\partightenfactor0

\fs26 \cf2 By formulating protein data as standard sequence data like sentences in a text corpus, standard NLP algorithms can be readily applied. More concretely, individual peptides are treated as individual sentences and amino acids are treated as words. In this article, the skip-gram model is used with a context window of size 5, 5 negative samples, and 15-dimensional vector space embedding. Various other dimensional size were explored, however, 15-dimen- sions gave the best results on 10-fold cross-validation of HLA- A*02:01 subtype. The entire post-processed dataset by \cf3 Luo et al. (2016) \cf2 was used to learn this new distributed representation. The 15-dimensional vector space distributed representation, HLA-Vec, is summarized in \cf3 Table 1 \cf2 \
}